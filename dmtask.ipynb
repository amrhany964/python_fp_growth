# -*- coding: utf-8 -*-
"""DMTask.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u1byQlP5zVVvEd3bVVmgZOPYZJCbNqCK

#**Data Mining Task**
the implementation of FP Growth Algorithm

##**First we start by reading our data and visualize it!**
"""

import pandas as pd
import numpy as np

df = pd.read_excel('/content/Horizontal_Format.xlsx')

df.head()

list_item = df['items'].copy()
print(list_item)

"""##**Add all our transactions in a set to filter the repeated the items**"""

all_Transactions = []
for i in list_item:
  items_in_transaction = []
  temp_set = set()
  for j in i:
    if j != ',' and j not in temp_set:
      items_in_transaction.append(j)
      temp_set.add(j)  #AYA :to filter items that are repeated in the same transaction (ex: C O O K I E ---> C O K I E)
  all_Transactions.append(items_in_transaction)
print(all_Transactions)

all_items = [] #Aya sherif
for i in list_item:
  for j in i:
    if j != ',':
      all_items.append(j)
print("All items:")
print(all_items)
unique_items = set(all_items)
print("Unique items:")
print(unique_items)

"""##**count the freq of each item and put the items in dictonary as keys and put the freq of each beside it**"""

dict_of_items = {}
for i in unique_items: # AYA : counts the frequency of each item
  count = 0
  for j in list_item:
    if i in j:
      count += 1
  dict_of_items[i] = count
print("Items and their frequencies:")
print(dict_of_items)

"""##**Add some helper functions**"""

min_support = input("Enter the minimum support: ")
def isFrequent(count, min_support): #AYA : returns true if the itemset is frequent
  return count >= int(min_support)

frequentItemsets = {} #AYA :dictionary of frequent itemsets only
for i in dict_of_items:
  if isFrequent(dict_of_items[i], min_support):
    frequentItemsets[i] = dict_of_items[i]

print("Frequent itemsets:")
print(frequentItemsets)

#descending function JANA
def descending(frequentItemsets):
  sorted_items=sorted(frequentItemsets.items(),key=lambda x:x[1],reverse=True) # JANA : reverse true means descending here, x[1] is the value aka count
  return sorted_items

sorted_items= dict(descending(frequentItemsets))
print("Frequent itemsets after sorting (descending):")
print(sorted_items)

print("Transactions before: ")
for transaction in all_Transactions:
  print(transaction)

def remove_arrange(transaction, sorted_items):
 filtered = [i for i in transaction if i in frequentItemsets]
 arranged = sorted(filtered, key=lambda x: sorted_items[x], reverse=True)
 return arranged

print("Transactions after having their items filtered and arranged: ")
for transaction in all_Transactions:
   transaction =remove_arrange(transaction, sorted_items)
   print(transaction)

"""##**Node class for each node in our tree**

"""

#omar note : nodes for tree
class node:
    def __init__(self,item,count,parent):
        self.item=item
        self.count=count
        self.parent=parent
        self.child={}
        self.next_similar = None
    def Update_Frequency(self,count):
        self.count=count

"""##**Tree class**"""

#omar note : tree class using the nodes
class Tree:
  #omar note  : the init dont take any arguments that intialize needs in our class
    def __init__(self):
        self.root=node(None,None,None) # root ->> NULL
        self.header_table = {}
    def insert(self,Transaction):#list of sorted items --> Amr HAny
        current_node=self.root
        for i in Transaction:
            if i in current_node.child: # AMR :Update the Frequency
              current_node.child[i].Update_Frequency(current_node.child[i].count + 1)
            else: #AMR : create a newNode
              NewNode=node(i,1,current_node)
              current_node.child[i]=NewNode
              if i in self.header_table:
                self.update_header_table(i, NewNode)
              else:
                self.header_table[i] = NewNode
            current_node=current_node.child[i]
    def update_header_table(self,item,new_node):
      """Omar note link nodes with the same item from header table"""
      current_node_in_chain = self.header_table[item]
      while current_node_in_chain.next_similar is not None:
            current_node_in_chain = current_node_in_chain.next_similar
      current_node_in_chain.next_similar = new_node
    def get_paths(self,item):
       """Omar note : Get all paths ending with the specified item"""
       paths = []
       current_linked_node = self.header_table.get(item)
       while current_linked_node is not None:
        path = []
        temp_node = current_linked_node.parent

        while temp_node.item is not None:
          path.append(temp_node.item)
          temp_node = temp_node.parent

        if path:
          paths.append((path[::-1], current_linked_node.count))
        current_linked_node = current_linked_node.next_similar
       return paths
    def print_tree(self,node=None,indent=""):
       if node is None:
          node = self.root
          print("FP-Tree Structure:")
          print("Root")

       for item, child in node.child.items():
          print(f"{indent}├── {item}:{child.count}")
          self.print_tree(child, indent + "│   ")
    #omar note : delete node using the FP Algo
    def delete(self,item):
      nodes_to_visit = [self.root]
      while nodes_to_visit:
        current_node = nodes_to_visit.pop()
        for child_item_name in list(current_node.child.keys()):
          child_node = current_node.child[child_item_name]
          if child_item_name == item and len(child_node.child)==0:
            del current_node.child[child_item_name]
          else:
            nodes_to_visit.append(child_node)

tree = Tree()
for transaction in all_Transactions:
    arranged_trans = remove_arrange(transaction, sorted_items)
    if arranged_trans:
        tree.insert(arranged_trans)

tree.print_tree()

"""##**Then we will do the FP Growth algorithm using Recursive algorithm**"""

def get_all_nodes(tree,item):
  """omar note: Get all nodes with the specified item from header table"""
  nodes_of_tree = []
  node = tree.header_table.get(item)
  while node is not None:
    nodes_of_tree.append(node)
    node = node.next_similar
  return nodes_of_tree

def fp_growth_algo(tree,prefix,min_support,Freq_patterns):
  """
  omar note :
  this is a fucntion that takes the tree as a parameter and min support
  where min support is the min support that counts a certain itemset as
  a frequent one and add to Freq patterns
  """
  #sort items based on there count
  items = sorted(tree.header_table.keys(), key=lambda x: sum(node.count for node in get_all_nodes(tree,x)))
  for item in items:
    new_pattern = prefix+[item]
    support = sum(node.count for node in get_all_nodes(tree,item))
    #omar note : check if their support are higher than the min if tho add to the array
    if support >= int(min_support):
      pattern_key = tuple(sorted(new_pattern))
      if pattern_key not in Freq_patterns:
        Freq_patterns[pattern_key] = support
        print(f"Pattern:{new_pattern}->Support:{support}")

      paths = tree.get_paths(item)
      if paths:
        conditional_tree = Tree()
        for path_data in paths:
          current_path = path_data[0]
          current_count = path_data[1]
          for _ in range(current_count):
            if current_path:
              conditional_tree.insert(current_path)

        if conditional_tree.header_table:
          fp_growth_algo(conditional_tree, new_pattern, min_support, Freq_patterns)

"""##**Test the FP Algo**"""

frequent_patterns = {}
for item, count in frequentItemsets.items():
    frequent_patterns[(item,)] = count
fp_growth_algo(tree, [], min_support, frequent_patterns)
print("All Frequent Patterns:")
sorted_patterns = sorted(frequent_patterns.items(), key=lambda x: (-len(x[0]), -x[1]))
for pattern, support in sorted_patterns:
    print(f"{list(pattern)} -> Support: {support}")

"""##**All possible frequent itemsets for the provided min support**"""

print("All frequent itemsets:")
sorted_patterns_L = sorted(frequent_patterns.items(), key=lambda x: (-len(x[0]), -x[1]), reverse = True)
current_length = 0
for pattern, support in sorted_patterns_L:
    pattern_length = len(pattern)
    if pattern_length != current_length:
        current_length = pattern_length
        print(f"\nL{current_length}:")
    print(f"  {list(pattern)} -> Support: {support}")

"""##**Get Association Rules**



"""

#jana
from itertools import combinations #JANA : make combinations for every itemset that have more than 2 items

def generate_association_rules(frequent_patterns):
  generated_rules=[]

  for itemset in frequent_patterns.keys():
    if len(itemset) < 2:
      continue

    for i in range(1,len(itemset)):
      for LHS in combinations(itemset,i):
        RHS = tuple(sorted(set(itemset) - set(LHS)))
        generated_rules.append({
            "LHS":sorted(LHS),
            "RHS":sorted(RHS)
            })
  return generated_rules

generated_rules = generate_association_rules(frequent_patterns)

for rule in generated_rules:
    print(f"Association Rule: {rule['LHS']} -> {rule['RHS']}")

"""
2.   evaluate the rules

"""

def evaluate_rules(frequent_patterns,generated_rules, all_Transactions):
  #JANA : FUNC that print the confidince and ther lift values
  results=[]

  for rule in generated_rules:
    lhs=tuple(sorted(rule["LHS"]))
    rhs=tuple(sorted(rule["RHS"]))
    union = tuple(sorted(set(lhs) | set(rhs)))

    lhs_support = frequent_patterns[lhs]
    rhs_support = frequent_patterns[rhs]
    union_support = frequent_patterns[union]

    if(lhs_support == 0 or rhs_support == 0 or union_support == 0):
      continue

    confidence = union_support / lhs_support
    lift = confidence / (rhs_support / len(all_Transactions))

    results.append({
        "LHS":rule["LHS"],
        "RHS":rule["RHS"],
        "Confidence":confidence,
        "Lift":lift
    })

  return results

rules = evaluate_rules(frequent_patterns,generated_rules, all_Transactions)
for rule in rules:
    print(f"Association Rule: {rule['LHS']} -> {rule['RHS']}")
    print(f"Confidence: {rule['Confidence']}")
    print(f"Lift: {rule['Lift']}")

def check_strong_rules(rules, min_confidence): #JANA function to get which are strong and which not
    strong_rules = []
    for rule in rules:
        if rule['Confidence'] >= min_confidence:
            strong_rules.append(rule)
    return strong_rules

min_confidence = float(input("Enter the minimum confidence: "))
strong_rules = check_strong_rules(rules, min_confidence)
print("Strong Association Rules:")
for rule in strong_rules:
    print(f"Association Rule: {rule['LHS']} -> {rule['RHS']}")
    print(f"Confidence: {rule['Confidence']}")
